\documentclass[10pt]{article}
\usepackage[spanish]{babel}
\usepackage{amsmath, amssymb, amsthm, tikz, cancel, mathtools}
\usepackage[margin=1in]{geometry}
\usetikzlibrary{babel}

\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corolario}[theorem]
\newtheorem{example}{Ejemplo}[section]

\title{Matemática Discreta 1}
\author{Santiago Sierra}

\begin{document}
    \maketitle \tableofcontents \newpage
    \section{Relaciones}
    \subsection{Definición de Relaciones}
    \begin{definition}
        Para los conjuntos $A,\ B \subseteq U$, el producto cartesiano de $A$ y $B$ se denota por $A\times B$, y $$A\times B=\{(a,b)\ /\ a\in A \wedge b\in B\}$$
    \end{definition}
    \begin{corollary}
        Notamos como $|A|$ al cardinal de un conjunto, que representa la cantidad de elementos en $A$.
    \end{corollary}
    \begin{corollary}
        Si los conjuntos $A,\ B$ son finitos, se sigue de la regla del producto que $|A\times B|=|A|\cdot|B|$.\\
        Aunque generalmente no ocurre que $A\times B=B\times A$, tenemos que $|A\times B|=|B\times A|$.
    \end{corollary}
    \begin{definition}
        Para los conjuntos $A,B\subseteq U$, cualquier subconjunto de $A\times B$ es una relación de $A$ en $B$.\\
        A los subconjuntos de $A\times A$ se les llama relaciones sobre $A$.
    \end{definition}
    \begin{definition}{Relación binaria}
        \\Una relación binaria es un conjunto de pares ordenados pertenecientes al producto cartesiano de dos conjuntos que cumple una propiedad $P(a,b)$ en particular, es decir: $$R=\{(a,b)\in A\times B\ /\ P(a,b)\}$$
        Notaremos como $aRb$ para indicar que $(a,b)\in R$ y $a\cancel{R}b$ para expresar que $(a,b)\notin R$
    \end{definition}
    \begin{corollary}
        En general, para conjuntos finitos $A,\ B$, existen $2^{|A\times B|}=2^{|A||B|}$ relaciones de $A$ en $B$, incluyendo la relación vacía y la propia relación $A\times B$.
    \end{corollary}
    \begin{definition}{Relación inversa}
        Si $R$ es una relación sobre $A$, entonces $R^{-1}$ es una relación sobre $A$ definida por $xRy\Leftrightarrow yR^{-1}x,\ \forall x,y\in A$.
        \\Es decir, da vuelta el par ordenado.
    \end{definition}
    \begin{corollary}
        $(R^{-1})^{-1}=R$.
    \end{corollary}
    \begin{corollary}
        $R\subseteq S\Rightarrow R^{-1}\subseteq S^{-1}$.
    \end{corollary}
    \begin{definition}
        $\overline{R}=R^C=A\times A-R=\{(a,b)\in A\times A: (a,b)\notin R\}$.\\
        $$a\overline{R}b\Leftrightarrow a\cancel{R}b$$
    \end{definition}
   \newpage\subsection{Tipos de relaciones}
    \begin{definition}
        Sea $R$ una relación en un conjunto $A$:
        \begin{itemize}
            \item La relación $R$ es reflexiva si: $$\forall a\in A,\ aRa$$
            \item La relación $R$ es irreflexiva si: $$\forall a\in A,\ a\cancel{R}a$$
            \item La relación $R$ es simétrica si: $$\forall a,b\in A, aRb\Leftrightarrow bRa$$
            \item La relación $R$ es anti-simétrica si: $$\begin{rcases}aRb\\bRa\end{rcases}\Rightarrow a=b$$
            \item La relación $R$ es asimétrica si: $$aRb\Rightarrow b\cancel{R}a$$
                Una relación asimétrica no puede ser reflexiva ni simétrica, e implica la anti-simétrica.
            \item La relación $R$ es transitiva si: $$\begin{rcases}aRb\\bRc\end{rcases}\Rightarrow aRc$$
        \end{itemize}
    \end{definition}
    \begin{corollary}
        $R$ es simétrica $\Leftrightarrow R=R^{-1}$.
    \end{corollary}
    \begin{corollary}
        Si $R$ es reflexiva, simétrica, etc, $R^{-1}$ es del mismo tipo.
    \end{corollary}
    \begin{definition}
        Una relación $R$ sobre un conjunto $A$ es un orden parcial, o una relación de orden parcial, si $R$ es reflexiva, anti-simétrica y transitiva.
    \end{definition}
    \begin{definition}
        Una relación de equivalencia $R$ sobre un conjunto $A$ es una relación que es reflexiva, simétrica y transitiva.
    \end{definition}
    \subsection{Producto, unión e intersección de relaciones}
    \begin{definition}
        Si $A,B,C$ son conjuntos y $R\subseteq A\times B$ y $S\subseteq B\times C$, entonces la relación compuesta $RS$ es una relación de $A$ en $C$ definida como $RS=\{(x,z) / x\in A \wedge z\in C \wedge \exists y\in B / (x,y)\in R \wedge (y,z)\in S \}$.
    \end{definition}
    \begin{theorem}
        Sean $A,B,C,D$ conjuntos y $R_1\subseteq A\times B,\ R_2\subseteq B\times C,\ R_3\subseteq C\times D$.\\Entonces $R_1(R_2R_3)=(R_1R_2)R_3$.
    \end{theorem}
    \begin{definition}
        Dado un conjunto $A$ y una relación $R$ sobre $A$, definimos las potencias de $R$ en forma recursiva como:
        \begin{itemize}
            \item $R^1=R$.
            \item Para $n\in\mathbb{Z}^+,\ R^{n+1}=R\ R^n$.
        \end{itemize}
    \end{definition}
    \begin{example}
        Si $A=\{1,2,3,4\}$ y $R=\{(1,2),(1,3),(2,4),(3,2)\}$, entonces $R^2=\{(1,4),(1,2),(3,4)\}$, $R^3=\{(1,4)\}$ y para $n\ge4,\ R^n=\emptyset$.
    \end{example}
    \newpage\subsection{Representación matricial y dígrafos}
    \subsubsection{Representación matricial}
    \begin{definition}
        Una matriz cero-uno $m\times n,\ E=(e_{ij})_{m\times n}$ es una disposición rectangular de números en $m$ filas y $n$ columnas, donde cada $e_{ij}$ para $1\le i\le m$, y $1\le j\le n$, denota la entrada de la i-esima columna de $E$ y cada una de dichas entradas es $0$ o $1$.
    \end{definition}
    \begin{definition}
        Si $R$ es una relación entre $A$ y $B$, entonces $R$ puede ser representado por la matriz $M$ cuyos indices de fila y columna indexan los elementos de $a$ y $b$, respectivamente, de manera que las entradas de $M$ quedan definidas por:$$m_{ij}=\begin{cases}1 & aRb\\0 & a\cancel{R}b\end{cases}$$
    \end{definition}
    \begin{corollary}
        Sea $A$ un conjunto y $R$ una relación sobre $A$, si $M(R)$ es la matriz de la relación, entonces:
        \begin{itemize}
            \item $M(R)=0$, la matriz con todos los elementos iguales a 0, si y sólo si $R=\emptyset$.
            \item $M(R)=1$, la matriz con todos los elementos iguales a 1, si y sólo si $R=A\times A$.
            \item $M(R^m)=[M(R)]^m,\ m\in\mathbb{Z}$.
        \end{itemize}
    \end{corollary}
    \begin{corollary}
        Sean $R$ y $S$ relaciones, y $M(R),\ M(S)$ sus matrices respectivamente,\\ entonces $M(R)\cdot M(S)=M(RS)$, pero ningún termino excede el $1$.
    \end{corollary}
    \begin{definition}
        Sean $E$ y $F$ dos matrices cero-uno $m\times n$. Decimos que $E$ es menor que $F$ y escribimos $E\le F$, si $e_{ij}\le f_{ij}$, para todos $1\le i\le m,\ 1\le j\le n$.\\
        En caso que exista al menos un elemento que no cumpla esto, las matrices no son comparables
    \end{definition}
    \begin{example}{ \ }\\
        $$\begin{pmatrix} 0 & 1\\1 & 0 \end{pmatrix}\le \begin{pmatrix} 1 & 1\\1 & 0 \end{pmatrix}$$ 
        $$\begin{pmatrix} 1 & 1\\1 & 0 \end{pmatrix} \cancel{\le} \begin{pmatrix} 0 & 1\\ 1 & 1 \end{pmatrix}\ \
        \begin{pmatrix} 0&1\\1&1 \end{pmatrix} \cancel{\le} \begin{pmatrix} 1&1\\1&0 \end{pmatrix} $$
    \end{example}\hfill\break
    \begin{definition}{Intersección o producto coordenada a coordenada}
        \\Si $M,\ N\in\mathcal{M}_{r\times s}\Rightarrow M\cap N\in\mathcal{M}_{r\times s} / (M\cap N)=M_{ij}\cdot N_{ij}$.
    \end{definition}
    \begin{theorem}
        Dado un conjunto $A$ con y una relación $R$ sobre $A$, sea $M$ la matriz de relación para $R$, entonces:
        \begin{itemize}
            \item $R$ es reflexiva $\Leftrightarrow Id_{|A|}\le M$. En el caso contrario, es irreflexiva.
            \item $R$ es simétrica $\Leftrightarrow M=M^t$.
            \item $R$ es transitiva $\Leftrightarrow MM=M^2\le M$.
            \item $R$ es anti-simétrica $\Leftrightarrow M\cap M^t\le Id_{|A|}$.\\
                Recordar, esta matriz se forma operando los elementos correspondientes de $M$ y $M^t$ con las reglas $0\cap0=0\cap1=1\cap0=0$ y $1\cap1=1$ (lo mismo que multiplicación coordenada a coordenada).
        \end{itemize}
    \end{theorem}
    \begin{corollary}
        Sean las relaciones $R,\ S$, y $M(R),\ M(S)$ las matrices de las relaciones, entonces:
        \begin{itemize}
            \item $M(R)^t=M(R^{-1})$.
            \item $M(R)+M(S)=M(R\cup S)$.
            \item $M(R)\cap M(S)=M(R\cap S)$.
        \end{itemize}
    \end{corollary}
    \begin{corollary}{Conteo de Relaciones}
        \\Sea $|A|=n$:
        \begin{itemize}
            \item Cantidad de relaciones reflexivas: $2^{n^2-n}$\\Tenemos 2 posibilidades, $0$ o $1$, en la diagonal siempre tiene que haber 1, y la matriz va a tener un total de $n^2$ entradas, y les restamos $n$ que son las entradas que ya están ocupadas por la diagonal.
            \item Cantidad de relaciones simétricas: $2^{\frac{n^2+n}{2}}$\\Devuelta, 2 posibilidades, la diagonal no importan las entradas si son $0$ o $1$, solo que sea simétrica, por lo que podemos elegir las entradas de la triangular superior y se determinan las del otro lado, que son $\frac{n^2-n}{2}$, pero les sumamos $n$ de la diagonal, $\frac{n^2-n}{2}+n=\frac{n^2+n}{2}$.
            \item Cantidad de relaciones anti-simétricas: $2^n3^{\frac{n^2-n}{2}}$\\Las posibilidades de la diagonal son $2^n$, y fuera de la diagonal, los elementos $m_{ij}$ y $m_{ji}$, pueden ser ambos $0$, o uno $0$ y el otro $1$, por lo que son 3 posibilidades, y determinando la triangular superior ya se determina el otro lado, y son $\frac{n^2-n}{2}$ entradas.
        \end{itemize}
    \end{corollary}
    \subsubsection{Dígrafos de relaciones}
    \begin{definition}
        Sea $A$ un conjunto finito no vació, un grafo dirigido o dígrafo $G$ sobre $A$ esta formado por los elementos de $A$, llamados vértices o nodo de $G$, y un subconjunto $E$ de $A\times A$, conocido como las aristas o arcos de $G$. Si $a,b\in V$ y $(a,b)\in E$, entonces existe una arista de $a$ a $b$.\\El vértice $a$ es el origen o fuente de la arista, y $b$ es el termino, o vértice terminal, y decimos que $b$ es adyacente desde $a$, y que $a$ es adyacente hacia $b$. Ademas, si $a\neq b$, entonces $(a,b)\neq(b,a)$. Una arista de la forma $(a,a)$ es una lazo en $a$.
    \end{definition}
    \subsection{Relaciones de equivalencia y particiones}
    \begin{definition}
        Dado un conjunto $A$ y un conjunto de indices $I$, sea $\emptyset\neq A_i \subseteq A\ \forall i\in I$. Entonces $\{A_i\}_{i\in I}$ es una partición de $A$ si $$A=\bigcup _{i\in I} A_{i} \ \ \text{y} \ \ A_{i} \cap A_{j} =\emptyset \ \forall i,j\in I\ /\ i\neq j$$
        Cada subconjunto $A$, es una celda o bloque de la partición.
    \end{definition}
    \begin{definition}
        Sea $R$ una relación de equivalencia sobre un conjunto $A$. Para cualquier $x\in A$, la clase de equivalencia de $x$, que se denota con $[x]$, se define como $[x]=\{y\in A\ /\ yRx\}$.
    \end{definition}
    \begin{theorem}
        Si $R$ es una relación de equivalencia sobre un conjunto $A$, y $x,y\in A$, entonces
        \begin{itemize}
            \item $x\in [x]$.
            \item $xRy \Leftrightarrow [x]=[y]$.
            \item $[x]\neq[y]\Rightarrow [x]\cap[y]=\emptyset$ o $[a]\cap[b]\Rightarrow [a]=[b]$.
        \end{itemize}
    \end{theorem}
    \begin{theorem}
        Si $A$ es un conjunto, entonces:
        \begin{itemize}
            \item Cualquier relación de equivalencia $R$ sobre $A$ induce una partición de $A$.
            \item Cualquier partición de $A$ da lugar a una relación de equivalencia $R$ sobre $A$.
        \end{itemize}
    \end{theorem}
    \begin{theorem}
        Para cualquier conjunto $A$, existe una correspondencia uno a uno entre el conjunto de relaciones de equivalencia sobre $A$ y el conjunto de particiones de $A$.
    \end{theorem}
    \begin{definition}
        Dada una relación de equivalencia $R$ en un conjunto $A$, se llama conjunto cociente de $A$ determinado por $R$ al conjunto formado por todas las clases de equivalencia. Se le representa por $A/R$. Es decir:$$A/R=\{[a] \ /\ a\in A\}$$
    \end{definition}
    \subsection{Conjuntos parcialmente ordenados}
    Para analizar el concepto de orden, sea $A$ un conjunto y $R$ una relación sobre $A$, el par $(A,R)$ es un conjunto parcialmente ordenado, si la relación sobre $A$ es un orden parcial.
    \begin{definition}{Diagrama de Hasse}
        \\En general, si $R$ es un orden parcial sobre un conjunto finito $A$, construimos un diagrama de Hasse para $R$ sobre $A$ trazando un segmento de $x$ hacia arriba, hacia $y$, si $x,y\in A$ son tales que $xRy$ y, lo que es mas importante, si no existe otro elemento $z\in A$ tal que $xRz$ y $zRy$. Si adoptamos el convenio de leer el diagrama de abajo hacia arriba, no es necesario dirigir las aristas.
    \end{definition}
    \begin{definition}
        Si $(A,R)$ es un conjunto parcialmente ordenado, decimos que $A$ es totalmente ordenado si $\forall x,y\in A$ ocurre que $xRy$ o $yRx$.\\
        En este caso, decimos que $R$ es un orden total.
    \end{definition}
    \begin{definition}
        Si $(A,R)$ es un conjunto parcialmente ordenado, entonces un elemento $x\in A$ es un elemento maximal de $A$ si $\forall a\in A,\ a\neq x\Rightarrow x\cancel{R}a$. Un elemento $y\in A$ es un elemento minimal de $A$ si $\forall b\in A,\ b\neq y\Rightarrow b\cancel{R}y$.
    \end{definition}
    \begin{theorem}
        Si $(A,R)$ es un conjunto parcialmente ordenado y $A$ es finito, entonces $A$ tiene un elemento maximal y uno minimal.
    \end{theorem}
    \begin{definition}
        Si $(A,R)$ es un conjunto parcialmente ordenado, entonces decimos que $x\in A$ es un elemento mínimo si $xRa\ \forall a\in A$. El elemento $y\in A$ es un elemento máximo si $aRy\ \forall a\in A$.
    \end{definition}
    \begin{theorem}
        Si el conjunto parcialmente ordenado $(A,R)$ tiene un elemento máximo o mínimo, entonces ese elemento es único.
    \end{theorem}
    \begin{definition}
        Sea $(A,R)$ un conjunto parcialmente ordenado con $B\subseteq A$. Un elemento $x\in A$ es una cota inferior de $B$ si $xRb\ \forall b\in B$. De manera similar, un elemento $y\in A$ es una cota superior de $B$ si $bRy\ \forall b\in B$.\\
        Un elemento $x'\in A$ es una máxima cota inferior o ínfimo de $B$ si es una cota inferior de $B$ y si para todas las demás cotas inferiores $x''$ de $B$ tenemos que $x''Rx'$. De forma análoga, $y'\in A$ es una mínima cota superior o supremo de $B$ si es una cota superior de $B$ y si $y'Ry''$ para todas las demás cotas superiores de $y''$ de $B$.
    \end{definition}
    \begin{theorem}
        Si $(A,R)$ es un conjunto parcialmente ordenado y $B\subseteq A$, entonces $B$ tiene a lo sumo un ínfimo y supremo.
    \end{theorem}
    \begin{definition}
        El conjunto parcialmente ordenado $(A,R)$ es un retículo si para cualesquiera $x,y\in A$, los elementos $sup\{x,y\}$ e $inf\{x,y\}$ existen en $A$.
    \end{definition}
    \begin{definition}{Cadena}
        \\Sea $B\subseteq A$, $B$ es cadena si $\forall a,b\in B\ aRb$ o $bRa$.
    \end{definition}
    \begin{definition}{Anticadena}
        \\Sea $B\subseteq A$, $B$ es anticadena si $\begin{cases} a\cancel{R}b\\b\cancel{R}a\end{cases}$ con $a\neq b$.
    \end{definition}
    \begin{theorem}
        Sea $n$ el largo de la cadena mas larga $\Rightarrow\ A$ se puede particionar en $n$ anticadenas disjuntas.\\
        Sea $m$ la cantidad de elementos de la anticadena mas grande $\Rightarrow\ A$ se puede particionar en $m$ cadenas disjuntas.
    \end{theorem}
    \newpage\section{Teoría de Grafos}
    \begin{definition}
        Sea $V$ un conjunto finito no vació, y sea $A\subseteq V\times V$. El par $(V,A)$ es un grafo sobre $V$, donde $V$ es el conjunto de vértices o nodos, y $A$ es su conjunto de aristas. Escribimos $G=(V,A)$ para denotar tal grafo.
    \end{definition}
    \begin{corollary}
        Para cualquier arista $(a,b)\in A$ se dice que:
        \begin{itemize}
            \item La arista $(a,b)$ es incidente con los vértices $a$ y $b$.
            \item $a,b$ son los extremos de $(a,b)$.
            \item $a$ es el origen de $(a,b)$.
            \item $b$ es el termino de $(a,b)$.
        \end{itemize}
    \end{corollary}
    \begin{definition}
        Dados dos vértices $u,v\in V$ con $G=(V,A)$, decimos que son vértices adyacentes si $(u,v)\in A$, ademas se dice que $u$ y $v$ son adyacentes, y que $u$ es adyacente hacia $v$.
    \end{definition}
    \begin{definition}
        Dados $v\in V,\ a\in A$ con $G=(V,A)$, decimos que la arista $a$ es incidente al vértice $v$ si $\exists u\in V$ tal que $a=(u,v)$.
    \end{definition}
    \begin{definition}
        Una arista de la forma $(a,a)$ es un lazo.
    \end{definition}
    \begin{definition}
        Un vértice $a\in V$ esta aislado cuando no hay ningún vértice adyacente con $a$.
    \end{definition}
    \begin{corollary}
        Un vértice con un lazo no está aislado.
    \end{corollary}
    \begin{definition}
        Dado $G=(V,A)$ grafo, llamamos:
        \begin{itemize}
            \item Orden de $G$ al número de vértices, $m=|V|$.
            \item Tamaño de $G$ al número de aristas, $n=|A|$.
        \end{itemize}
    \end{definition}
    \begin{definition}{Camino}
        \\Sea $G=(V,A)$ un grafo, un camino (en $G$) es una sucesión finita y alternada de vértices y aristas, de la forma: $$c=v_0,a_1,v_1,a_2,v_2,\dots,v_{n-1},a_n,v_n$$donde $a_i=(v_{i-1},v_i)$ y $1\le i\le n$.\\Siendo $n$ el número de aristas.
    \end{definition}
    \begin{corollary}
        Un camino puede repetir vértices y/o aristas.
    \end{corollary}
    \begin{definition}
        Un camino $c=v_0,\dots,v_n$ esta cerrado cuando $v_0=v_n$. De otra forma, esta abierto.
    \end{definition}
    \begin{definition}
        Un recorrido es un camino sin repetición de aristas.
    \end{definition}
    \begin{definition}
        Un camino simple es un camino sin repetición de vértices (con la excepción posible de los extremos).
    \end{definition}
    \begin{definition}
        Un ciclo es un camino simple cerrado.
    \end{definition}
    \begin{corollary}
        Un ciclo de longitud 1 es un lazo.
        \begin{itemize}
            \item En un grafo dirigido, pueden existir ciclos de longitud 2.
            \item En un grafo no dirigido todos los ciclos tienen longitud $\ge 3$.
        \end{itemize}
    \end{corollary}
\end{document}
